{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title å®‰è£…ç¯å¢ƒ\n",
    "import os\n",
    "import time\n",
    "from IPython.utils import capture\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "# å¿½ç•¥è­¦å‘Š\n",
    "import warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "!git config --global advice.detachedHead false\n",
    "!sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' {warnings.__file__}\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def check_gpu():\n",
    "    import tensorflow as tf\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) > 0:\n",
    "      print(\"\\033[96m GPU is available.\\033[0m\", flush=True)\n",
    "    else:\n",
    "      print(\"\\033[91m æ²¡æœ‰ä½¿ç”¨GPU,è¯·åœ¨ä»£ç æ‰§è¡Œç¨‹åº-æ›´æ”¹è¿è¡Œæ—¶ç±»å‹-è®¾ç½®ä¸ºGPU!\\033[0m\", flush=True)\n",
    "      display(HTML(\"<img src='https://i.ibb.co/xfb7pB7/check-gpu.png' width='560px'/>\"))\n",
    "      from google.colab import runtime\n",
    "      runtime.unassign()\n",
    "\n",
    "%cd /content\n",
    "#@markdown ###<font color=\"#11659a\"> é€‰æ‹©ç‰ˆæœ¬ï¼š</font>\n",
    "_version = \"Fooocus\" # @param [\"Fooocus\", \"SimpleSDXL\"]\n",
    "#@markdown #####<font color=\"#2c9678\">â˜‘æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†GPUï¼›â˜ä¸æ£€æŸ¥ã€‚\n",
    "_check_gpu = False  #@param {type:\"boolean\"}\n",
    "\n",
    "if _check_gpu:\n",
    "  check_gpu()\n",
    "start_time = time.time()\n",
    "if _version == \"Fooocus\":\n",
    "  git_url = \"https://github.com/lllyasviel/Fooocus\"\n",
    "elif _version == \"RuinedFooocus\":\n",
    "  git_url = \"https://github.com/runew0lf/RuinedFooocus\"\n",
    "elif _version == \"Fooocus-ControlNet-SDXL\":\n",
    "  git_url = \"https://github.com/fenneishi/Fooocus-ControlNet-SDXL\"\n",
    "elif _version == \"Fooocus-MRE\":\n",
    "  git_url = \"https://github.com/MoonRide303/Fooocus-MRE\"\n",
    "elif _version == \"SimpleSDXL\":\n",
    "  git_url = \"https://github.com/metercai/SimpleSDXL\"\n",
    "\n",
    "!git clone -q --depth 1  {git_url}\n",
    "print('é¡¹ç›®å…‹éš†æˆåŠŸï¼')\n",
    "main_dir = f\"/content/{_version}\"\n",
    "print(\"æ­£åœ¨å®‰è£…ç¯å¢ƒ,å¤§çº¦éœ€è¦ä¸¤åˆ†é’Ÿ...\")\n",
    "\n",
    "%cd {main_dir}\n",
    "if os.path.exists(\"settings-no-refiner.json\"):\n",
    "  !cp settings-no-refiner.json settings.json\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  !apt-get -qq -y update\n",
    "  !apt -y install -qq aria2\n",
    "  !pip install -q pyngrok pycloudflared -U\n",
    "  !pip uninstall -y lida llmx\n",
    "  !pip install kaleido cohere openai tiktoken typing-extensions==4.8.0 tensorflow-probability==0.13.0 dopamine-rl\n",
    "  !pip install -q -r requirements_versions.txt\n",
    "  !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://raw.githubusercontent.com/metercai/SimpleSDXL/SimpleSDXL/language/cn.json -d {main_dir}/language -o cn.json\n",
    "  !wget -q https://huggingface.co/Vanwise/sd-colab/resolve/main/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
    "%env LD_PRELOAD=/content/libtcmalloc_minimal.so.4\n",
    "end_time = time.time()\n",
    "print(\"ç¯å¢ƒå®‰è£…å®Œæˆï¼Œè€—æ—¶ï¼š{:.3f}åˆ†é’Ÿ.\".format((end_time - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /content/wise.py\n",
    "replace_download_models(_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cn = True  #@param {type:\"boolean\"}\n",
    "ip = True  #@param {type:\"boolean\"}\n",
    "face = True  #@param {type:\"boolean\"}\n",
    "\n",
    "default_models = \"sai\" # @param [\"juggernautXL\", \"realistic\", \"anime\", \"sai\", \"\"]\n",
    "ckpt_link = \"\" # @param {type:\"string\"}\n",
    "loars_link = \"\" # @param {type:\"string\"}\n",
    "emb_link = \"\" # @param {type:\"string\"}\n",
    "_inpaint = \"v2.6\" # @param [\"v1\", \"v2.5\", \"v2.6\"]\n",
    "\n",
    "presets = \"\"\n",
    "if default_models == \"juggernautXL\":\n",
    "    add_juggernautxl(main_dir)\n",
    "    presets = \"\"\n",
    "elif default_models == \"realistic\":\n",
    "    add_realistic(main_dir)\n",
    "    presets = \"--preset realistic\"\n",
    "elif default_models == \"anime\":\n",
    "    add_anime(main_dir)\n",
    "    presets = \"--preset anime\"\n",
    "elif default_models == \"sai\":\n",
    "    add_sai(main_dir)\n",
    "    presets = \"--preset sai\"\n",
    "\n",
    "if ckpt_link and default_models == \"\":\n",
    "    set_default_ckpt(main_dir, ckpt_link)\n",
    "\n",
    "if loars_link and default_models == \"\":\n",
    "    set_default_loars(main_dir, loars_link)\n",
    "\n",
    "add_controlnet(main_dir,cn,ip,face)\n",
    "add_other(main_dir)\n",
    "add_vaeapp(main_dir)\n",
    "add_custom_ckpt(main_dir,ckpt_link)\n",
    "add_custom_loras(main_dir,loars_link)\n",
    "add_custom_embeddings(main_dir,emb_link)\n",
    "add_inpaint(main_dir,_inpaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_download_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title (ğŸ”†)MODï¼\n",
    "# @markdown #### ğŸ’ ç”¨äºä¸‹è½½ä¸»æ¨¡å‹ã€Loraã€Vaeã€Embedding.\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from google.colab import files, drive\n",
    "from concurrent import futures\n",
    "\n",
    "# @markdown #### å¯ç”¨MOD:\n",
    "enable_mod = True #@param {type:\"boolean\"}\n",
    "# @markdown #### æ¨¡å‹ä¸‹è½½ä½ç½®:\n",
    "modown_dir = \"colab\" # @param [\"colab\", \"drive\"]\n",
    "if modown_dir == \"drive\":\n",
    "  modelr_dir = \"/content/drive/MyDrive/sd_models\"\n",
    "else:\n",
    "  modelr_dir = f\"{main_dir}/models/\"\n",
    "# @markdown ---\n",
    "# @markdown ##### [MODé“¾æ¥](https://docs.google.com/spreadsheets/d/1sp_o8fUBZk8BrThY9w1LeLd2aTuq41sT/edit#gid=149213849):\n",
    "mod_link = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vR_4_XVd-OxQQlCLQo99dnRCi2bBJtjg8Et_gQfgd_-g6j9ltuBAbiwPC6qSJy6_KNi-G_bPZdqrv-y/pub?output=xlsx\"# @param {type:\"string\"}\n",
    "# @markdown ##### MODè·¯å¾„:\n",
    "mod_path = \"/content/drive/MyDrive/wise.xlsx\"# @param {type:\"string\"}\n",
    "# @markdown ##### ä»£ç é€»è¾‘:ä¼˜å…ˆä½¿ç”¨MODé“¾æ¥,é“¾æ¥ä¸ºç©ºä½¿ç”¨MODè·¯å¾„,è·¯å¾„ä¸ºç©ºä½¿ç”¨ä¸Šä¼ MODã€‚\n",
    "\n",
    "def checkmod_link(link):\n",
    "  response = requests.get(link)\n",
    "  if response.status_code == 200:\n",
    "      content = response.content\n",
    "      try:\n",
    "          df = pd.read_excel(BytesIO(content))\n",
    "          print(\"MODè¯»å–æˆåŠŸ!\")\n",
    "          return df\n",
    "          #print(df.head())\n",
    "      except Exception as e:\n",
    "          print(\"æ— æ³•æ­£ç¡®è¯»å–æ–‡ä»¶,è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦ä¸º'.xlsx' :\", str(e))\n",
    "  else:\n",
    "      print(\"æ— æ³•è·å–æ–‡ä»¶,è¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æ­£ç¡®!\")\n",
    "\n",
    "def checkmod_path(path):\n",
    "  try:\n",
    "    df = pd.read_excel(path)\n",
    "    print(\"MODè¯»å–æˆåŠŸ!\")\n",
    "    return df\n",
    "    #print(df.head())\n",
    "  except Exception as e:\n",
    "    print(\"æ— æ³•æ­£ç¡®è¯»å–æ–‡ä»¶,è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦ä¸º'.xlsx' :\", str(e))\n",
    "\n",
    "def checkmod_up():\n",
    "    while True:\n",
    "        try:\n",
    "            uploaded = files.upload()\n",
    "            if not uploaded:\n",
    "                print(\"å–æ¶ˆä¸Šä¼ ,ä½¿ç”¨é»˜è®¤MOD!\")\n",
    "                mod = 'https://github.com/Van-wise/sd-colab/raw/main/wise.xlsx'\n",
    "                df = pd.read_excel(mod)\n",
    "                break\n",
    "            mod_file = os.path.join(os.getcwd(), list(uploaded.keys())[0])\n",
    "            df = pd.read_excel(mod_file)\n",
    "            print(\"MODè¯»å–æˆåŠŸ!\")\n",
    "            break  # Exit the loop if the file is successfully read\n",
    "\n",
    "        except (ValueError, Exception) as e:\n",
    "            os.remove(mod_file)\n",
    "            print(\"æ— æ³•æ­£ç¡®è¯»å–æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦ä¸º'.xlsx':\", str(e))\n",
    "            print(\"è¯·é‡æ–°ä¸Šä¼ æ–‡ä»¶ã€‚\")\n",
    "    return df\n",
    "\n",
    "def download_mod(file_dLlink, save_dir, file_name, index):\n",
    "    try:\n",
    "        os.system(f\"aria2c --console-log-level=error -q -c -x 16 -s 16 -k 1M {file_dLlink} -d {save_dir} -o {file_name}\")\n",
    "        print(f\"ç¬¬{index+1}è¡Œ:{file_name}ä¸‹è½½æˆåŠŸ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"ç¬¬{index+1}è¡Œ:{file_name}æ–‡ä»¶ä¸‹è½½é”™è¯¯ï¼š\", e)\n",
    "\n",
    "from concurrent import futures\n",
    "\n",
    "def start_mod():\n",
    "    if mod_link:\n",
    "        df = checkmod_link(mod_link)\n",
    "    elif mod_path:\n",
    "        df = checkmod_path(mod_path)\n",
    "    else:\n",
    "        df = checkmod_up()\n",
    "    df = df.fillna(\"\")\n",
    "\n",
    "    with futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_index = {}\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            file_switch, file_name, file_type, file_dLlink = row[[\"å¼€å…³\", \"åç§°\", \"ç±»å‹\", \"ä¸‹è½½åœ°å€\"]]\n",
    "\n",
    "            if any(value == \"\" for value in [file_switch, file_name, file_type, file_dLlink]):\n",
    "                print(f\"è·³è¿‡,ç¬¬{index+1}è¡Œ,å› ä¸º:|{'|'.join([key for key, value in row.items() if value == ''])}|çš„å†…å®¹ä¸èƒ½ä¸ºç©º!\")\n",
    "                continue\n",
    "\n",
    "            save_dir = os.path.join(modelr_dir, file_type)\n",
    "            file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "            if not os.path.exists(file_path) and file_switch == \"on\":\n",
    "                future = executor.submit(download_mod, file_dLlink, save_dir, file_name, index)\n",
    "                future_to_index[future] = index\n",
    "\n",
    "        for future in futures.as_completed(future_to_index):\n",
    "            index = future_to_index[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"ç¬¬{index+1}è¡Œä¸‹è½½é”™è¯¯:\", e)\n",
    "    print(\"MODè¿è¡Œå®Œæˆ...ğŸ‰\")\n",
    "\n",
    "if enable_mod:\n",
    "  !apt-get -qq install -y aria2\n",
    "  start_mod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title (ğŸ”†)MODï¼\n",
    "# @markdown #### ğŸ’ ç”¨äºä¸‹è½½ä¸»æ¨¡å‹ã€Loraã€Vaeã€Embedding.\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from google.colab import files, drive\n",
    "from concurrent import futures\n",
    "\n",
    "# @markdown #### å¯ç”¨MOD:\n",
    "enable_mod = True #@param {type:\"boolean\"}\n",
    "# @markdown #### æ¨¡å‹ä¸‹è½½ä½ç½®:\n",
    "modown_dir = \"colab\" # @param [\"colab\", \"drive\"]\n",
    "if modown_dir == \"drive\":\n",
    "  modelr_dir = \"/content/drive/MyDrive/sd_models\"\n",
    "else:\n",
    "  modelr_dir = f\"{main_dir}/models/\"\n",
    "# @markdown ---\n",
    "# @markdown ##### [MODé“¾æ¥](https://docs.google.com/spreadsheets/d/1o-13mwJiydTprn9OQHia2bWCirCwyLDvt2-OoWT5Trg/edit#gid=149213849):\n",
    "mod_link = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vR_4_XVd-OxQQlCLQo99dnRCi2bBJtjg8Et_gQfgd_-g6j9ltuBAbiwPC6qSJy6_KNi-G_bPZdqrv-y/pub?output=xlsx\"# @param {type:\"string\"}\n",
    "# @markdown ##### MODè·¯å¾„:\n",
    "mod_path = \"/content/drive/MyDrive/wise.xlsx\"# @param {type:\"string\"}\n",
    "# @markdown ##### ä»£ç é€»è¾‘:ä¼˜å…ˆä½¿ç”¨MODé“¾æ¥,é“¾æ¥ä¸ºç©ºä½¿ç”¨MODè·¯å¾„,è·¯å¾„ä¸ºç©ºä½¿ç”¨ä¸Šä¼ MODã€‚\n",
    "\n",
    "if enable_mod:\n",
    "  !apt-get -qq install -y aria2\n",
    "  start_mod(mod_link,mod_path,modelr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title å†…ç½‘ç©¿é€\n",
    "import os\n",
    "import shlex\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "# @markdown #### [Ngrok](https://dashboard.ngrok.com/get-started/your-authtoken):\n",
    "use_ngrok = True # @param {type:\"boolean\"}\n",
    "ngrok_token = \"2Wl6oIN6RPlyMnEg25bFjMjUn8n_4bUz2gmvBLc6dSrGZ3Bng\" # @param {type:\"string\"}\n",
    "# @markdown #### cloudflare:\n",
    "use_cloudflare = True # @param {type:\"boolean\"}\n",
    "# @markdown #### remote:\n",
    "use_remote = True # @param {type:\"boolean\"}\n",
    "\n",
    "def gen_key(path: Union[str, Path]) -> None:\n",
    "    path = Path(path)\n",
    "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
    "    args = shlex.split(arg_string)\n",
    "    subprocess.run(args, check=True)\n",
    "    path.chmod(0o600)\n",
    "\n",
    "if use_remote:\n",
    "  id_rsa_file = \"/content/id_rsa\"\n",
    "  id_rsa_pub_file = \"/content/id_rsa/id_rsa.pub\"\n",
    "  if os.path.exists(id_rsa_file):\n",
    "      os.remove(id_rsa_file)\n",
    "  if os.path.exists(id_rsa_pub_file):\n",
    "      os.remove(id_rsa_pub_file)\n",
    "  ssh_name = \"id_rsa\"\n",
    "  ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
    "  gen_key(ssh_path)\n",
    "\n",
    "if use_ngrok:\n",
    "  from pyngrok import ngrok\n",
    "  ngrok.set_auth_token(ngrok_token)\n",
    "\n",
    "def start_tunnle():\n",
    "  time.sleep(5)\n",
    "  # open(\"/content/output.log\", \"w\").close()\n",
    "  # # å¾ªç¯æ£€æµ‹æ–‡ä»¶å†…å®¹ï¼Œç›´åˆ°å­˜åœ¨\"http://127.0.0.1:9090\"ã€‚\n",
    "  # while not \"http://127.0.0.1:7865\" in open(\"/content/output.log\", \"r\").read():\n",
    "  #   time.sleep(1)\n",
    "\n",
    "  clear_output()\n",
    "  from IPython.display import display, HTML\n",
    "  audio_url = \"https://github.com/Van-wise/sd-colab/raw/main/qidong.mp3\"\n",
    "  display(HTML(f'<audio src=\"{audio_url}\" controls autoplay style=\"display:none\"></audio>'))\n",
    "\n",
    "  if use_ngrok:\n",
    "      try:\n",
    "          from pyngrok import ngrok\n",
    "          ngrok_tunnel = ngrok.connect(7865, \"http\")\n",
    "          print(\"ngrok_tunnel:\", ngrok_tunnel)\n",
    "      except Exception as e:\n",
    "          print(\"ngrok è¿æ¥å¤±è´¥ï¼š\", e)\n",
    "\n",
    "  if use_cloudflare:\n",
    "      try:\n",
    "          from pycloudflared import try_cloudflare\n",
    "          cloudflare_url = try_cloudflare(7865, verbose=False)\n",
    "          print(\"cloudflare_tunnel:\", cloudflare_url)\n",
    "      except Exception as e:\n",
    "          print(\"cloudflare è¿æ¥å¤±è´¥ï¼š\", e)\n",
    "\n",
    "  if use_remote:\n",
    "      !ssh -R 80:127.0.0.1:7865 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe 2>&1 | tee -a /content/tunnel.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "thread = threading.Thread(target=start_tunnle, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "#!python entry_with_update.py --language zh --port 7685\n",
    "!python launch.py --language cn --port 7865 $presets"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
