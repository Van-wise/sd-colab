{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFS9SSqgTBgX"
      },
      "source": [
        "###  <a href='https://ko-fi.com/P5P1QO6VB' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://storage.ko-fi.com/cdn/kofi4.png?v=3' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UokR0q1ITH3i"
      },
      "source": [
        "<div style=\"display: flex; justify-content: center; align-items: center;\">\n",
        "    <img src=\"https://i.ibb.co/w6ngBsW/20231031152934.jpg\" alt=\"20231031152934\" width=\"300\">\n",
        "    <span style=\"margin: 0 20px;\">|</span>\n",
        "    <img src=\"https://i.ibb.co/SrxYKmz/20231031152928.jpg\" alt=\"20231031152928\" width=\"400\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNKmTVtoTLei"
      },
      "source": [
        "## VoltaML_colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS76MeACTR7L"
      },
      "source": [
        "---\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Van-wise/sd-colab/blob/main/voltaml/voltaml.ipynb)\n",
        "[![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fcolab.research.google.com%2Fgithub%2FVan-wise%2Fsd-colab%2Fblob%2Fmain%2Fvoltaml%2Fvoltaml.ipynb&labelColor=%232ccce4&countColor=%23555555&style=flat&labelStyle=upper)](https://visitorbadge.io/status?path=https%3A%2F%2Fcolab.research.google.com%2Fgithub%2FVan-wise%2Fsd-colab%2Fblob%2Fmain%2Fvoltaml%2Fvoltaml.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<font color=\"red\">**Êõ¥Êñ∞Âú∞ÂùÄ**Ôºöhttps://github.com/Van-wise/sd-colab\n",
        "\n",
        "**Â¶ÇÊûúÈÅáÂà∞Êä•Èîô,ËØ∑ËÅîÁ≥ªupÔºö**\n",
        "[bilibili](https://space.bilibili.com/1308057/channel/collectiondetail?sid=1365244) or [issues](https://github.com/Van-wise/sd-colab/issues)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "orFKHKfzTQlb"
      },
      "outputs": [],
      "source": [
        "# @title (üîÜ)ÂÆâË£ÖÁéØÂ¢É\n",
        "import os\n",
        "import time\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output, display, HTML\n",
        "\n",
        "# ÂøΩÁï•Ë≠¶Âëä\n",
        "import warnings\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "!git config --global advice.detachedHead false\n",
        "!sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' {warnings.__file__}\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def check_gpu():\n",
        "    import tensorflow as tf\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    if len(physical_devices) > 0:\n",
        "      print(\"\\033[96m GPU is available.\\033[0m\", flush=True)\n",
        "    else:\n",
        "      print(\"\\033[91m Ê≤°Êúâ‰ΩøÁî®GPU,ËØ∑Âú®‰ª£Á†ÅÊâßË°åÁ®ãÂ∫è-Êõ¥ÊîπËøêË°åÊó∂Á±ªÂûã-ËÆæÁΩÆ‰∏∫GPU!\\033[0m\", flush=True)\n",
        "      display(HTML(\"<img src='https://i.ibb.co/xfb7pB7/check-gpu.png' width='560px'/>\"))\n",
        "      from google.colab import runtime\n",
        "      runtime.unassign()\n",
        "\n",
        "%cd /content\n",
        "#@markdown ###<font color=\"#11659a\"> ÈÄâÊã©ÁâàÊú¨Ôºö</font>\n",
        "_branch = \"main\" # @param [\"v0.5.0\", \"v0.4.2\", \"main\"]\n",
        "#@markdown #####<font color=\"#2c9678\">‚òëÊ£ÄÊü•ÊòØÂê¶‰ΩøÁî®‰∫ÜGPUÔºõ‚òê‰∏çÊ£ÄÊü•„ÄÇ\n",
        "_check_gpu = True  #@param {type:\"boolean\"}\n",
        "# @markdown #####Â°´ÂÜôÔºö[HUGGINGFACE_TOKEN](https://huggingface.co/settings/tokens)\n",
        "hf_token = \"1\" # @param {type:\"string\"}\n",
        "os.environ['HUGGINGFACE_TOKEN'] = hf_token\n",
        "\n",
        "if _check_gpu:\n",
        "  check_gpu()\n",
        "start_time = time.time()\n",
        "\n",
        "!git clone -q -b {_branch} https://github.com/VoltaML/voltaML-fast-stable-diffusion\n",
        "print('È°πÁõÆÂÖãÈöÜÊàêÂäüÔºÅ')\n",
        "main_dir = \"/content/voltaML-fast-stable-diffusion\"\n",
        "print(\"Ê≠£Âú®ÂÆâË£ÖÁéØÂ¢É,Â§ßÁ∫¶ÈúÄË¶Å‰∏âÂàÜÈíü...\")\n",
        "\n",
        "%cd {main_dir}\n",
        "with capture.capture_output() as cap:\n",
        "  !apt-get -qq -y update\n",
        "  !apt -y install -qq aria2\n",
        "  !aria2c --console-log-level=error -q -c -x 16 -s 16 -k 1M https://github.com/Van-wise/sd-colab/raw/main/voltaml/wise.py -d /content -o wise.py\n",
        "  %run /content/wise.py\n",
        "  fix_colab(main_dir)\n",
        "  !pip uninstall -y lida llmx\n",
        "  !pip install -q kaleido cohere openai tiktoken jedi\n",
        "  !python main.py --install-only\n",
        "end_time = time.time()\n",
        "print(\"ÁéØÂ¢ÉÂÆâË£ÖÂÆåÊàêÔºåËÄóÊó∂Ôºö{:.3f}ÂàÜÈíü.\".format((end_time - start_time) / 60))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrhNrPxY6yqy"
      },
      "source": [
        "###  üåê‰∏ãËΩΩÊ®°Âûã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Gzq3KPdL6_ti"
      },
      "outputs": [],
      "source": [
        "# @title (üîÜ)MODÔºÅ\n",
        "# @markdown #### üí†Áî®‰∫é‰∏ãËΩΩ‰∏ªÊ®°Âûã„ÄÅLora„ÄÅVae„ÄÅEmbedding.\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from google.colab import files, drive\n",
        "from concurrent import futures\n",
        "\n",
        "# @markdown #### ÂêØÁî®MOD:\n",
        "enable_mod = True #@param {type:\"boolean\"}\n",
        "# @markdown #### Ê®°Âûã‰∏ãËΩΩ‰ΩçÁΩÆ:\n",
        "modown_dir = \"colab\" # @param [\"colab\", \"drive\"]\n",
        "if modown_dir == \"drive\":\n",
        "  modelr_dir = \"/content/drive/MyDrive/sd_models\"\n",
        "else:\n",
        "  modelr_dir = f\"{main_dir}/data/\"\n",
        "# @markdown ---\n",
        "# @markdown ##### [MODÈìæÊé•](https://docs.google.com/spreadsheets/d/1aRQNNgCpnDZt_mLOuBOAjeoz-osm_7MS/edit#gid=149213849):\n",
        "mod_link = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vS0Jie7yPe6EDJDYepjXxH7muvEib-linridXHWNDC9Y09Wjp6zeY4JmBTQdwke0w/pub?output=xlsx\"# @param {type:\"string\"}\n",
        "# @markdown ##### MODË∑ØÂæÑ:\n",
        "mod_path = \"/content/drive/MyDrive/wise.xlsx\"# @param {type:\"string\"}\n",
        "# @markdown ##### ‰ª£Á†ÅÈÄªËæë:‰ºòÂÖà‰ΩøÁî®MODÈìæÊé•,ÈìæÊé•‰∏∫Á©∫‰ΩøÁî®MODË∑ØÂæÑ,Ë∑ØÂæÑ‰∏∫Á©∫‰ΩøÁî®‰∏ä‰º†MOD„ÄÇ\n",
        "\n",
        "if enable_mod:\n",
        "  !apt-get -qq install -y aria2\n",
        "  start_mod(mod_link,mod_path,modelr_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "IWbaa5kFl0Cv"
      },
      "outputs": [],
      "source": [
        "# @title ÂÜÖÁΩëÁ©øÈÄè\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "# @markdown #### [Ngrok](https://dashboard.ngrok.com/get-started/your-authtoken):\n",
        "use_ngrok = False # @param {type:\"boolean\"}\n",
        "ngrok_token = \"\" # @param {type:\"string\"}\n",
        "# @markdown #### cloudflare:\n",
        "use_cloudflare = True # @param {type:\"boolean\"}\n",
        "# @markdown #### remote:\n",
        "use_remote = True # @param {type:\"boolean\"}\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "if use_remote:\n",
        "  id_rsa_file = \"/content/id_rsa\"\n",
        "  id_rsa_pub_file = \"/content/id_rsa/id_rsa.pub\"\n",
        "  if os.path.exists(id_rsa_file):\n",
        "      os.remove(id_rsa_file)\n",
        "  if os.path.exists(id_rsa_pub_file):\n",
        "      os.remove(id_rsa_pub_file)\n",
        "  ssh_name = \"id_rsa\"\n",
        "  ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "  gen_key(ssh_path)\n",
        "\n",
        "if use_ngrok:\n",
        "  from pyngrok import ngrok\n",
        "  ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "def start_tunnle():\n",
        "  #time.sleep(1)\n",
        "  open(\"/content/output.log\", \"w\").close()\n",
        "  # Âæ™ÁéØÊ£ÄÊµãÊñá‰ª∂ÂÜÖÂÆπÔºåÁõ¥Âà∞Â≠òÂú®\"http://127.0.0.1:9090\"„ÄÇ\n",
        "  while not \"numexpr.utils\" in open(\"/content/output.log\", \"r\").read():\n",
        "    time.sleep(1)\n",
        "\n",
        "  clear_output()\n",
        "  from IPython.display import display, HTML\n",
        "  audio_url = \"https://github.com/Van-wise/sd-colab/raw/main/qidong.mp3\"\n",
        "  display(HTML(f'<audio src=\"{audio_url}\" controls autoplay style=\"display:none\"></audio>'))\n",
        "\n",
        "  if use_ngrok:\n",
        "      try:\n",
        "          from pyngrok import ngrok\n",
        "          ngrok_tunnel = ngrok.connect(5003, \"http\")\n",
        "          print(\"ngrok_tunnel:\", ngrok_tunnel)\n",
        "      except Exception as e:\n",
        "          print(\"ngrok ËøûÊé•Â§±Ë¥•Ôºö\", e)\n",
        "\n",
        "  if use_cloudflare:\n",
        "      try:\n",
        "          from pycloudflared import try_cloudflare\n",
        "          cloudflare_url = try_cloudflare(5003, verbose=False)\n",
        "          print(\"cloudflare_tunnel:\", cloudflare_url)\n",
        "      except Exception as e:\n",
        "          print(\"cloudflare ËøûÊé•Â§±Ë¥•Ôºö\", e)\n",
        "\n",
        "  if use_remote:\n",
        "      !ssh -R 80:127.0.0.1:5003 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe 2>&1 | tee -a /content/tunnel.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Oq4fYxZoDEX"
      },
      "source": [
        "### (‚öí)ÈôÑÂä†ÂäüËÉΩÔºö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tABVG-LhoIFl"
      },
      "outputs": [],
      "source": [
        "# @markdown #### üåê‰ΩøÁî®‰∫ëÁõòÊ®°Âûã:\n",
        "use_drivemodels = False # @param {type:\"boolean\"}\n",
        "gmodelr_dir = \"/content/drive/MyDrive/sd_models\" # @param [\"/content/drive/MyDrive/sd_models\"] {allow-input: true}\n",
        "# @markdown #### üìÅÊâìÂåÖËæìÂá∫ÂõæÁâá:\n",
        "use_zipoutputs = True # @param {type:\"boolean\"}\n",
        "#@markdown #####‰øùÂ≠òÈó¥ÈöîÔºàÁßíÔºâÔºö\n",
        "save_interval = 120 #@param {type:\"integer\"}\n",
        "#@markdown #####ÂéãÁº©‰øùÂ≠òÁõÆÂΩïÔºö\n",
        "zip_path = \"/content/outputs\" # @param [\"/content/outputs\", \"/content/drive/MyDrive/outputs\"] {allow-input: true}\n",
        "\n",
        "if zip_path == \"/content/drive/MyDrive/outputs\":\n",
        "  if not os.path.exists('/content/drive/'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print('Google Drive ÊåÇËΩΩÊàêÂäüÔºÅ')\n",
        "    os.makedirs('/content/drive/MyDrive/outputs', exist_ok=True)\n",
        "\n",
        "\n",
        "import os\n",
        "def content_models():\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print('Google Drive ÊåÇËΩΩÊàêÂäüÔºÅ')\n",
        "\n",
        "  for modelver in [\"models\", \"lora\", \"lycoris\", \"vae\", \"onnx\"]:\n",
        "      sub_dir_path = f\"{gmodelr_dir}/{modelver}\"\n",
        "      os.makedirs(sub_dir_path, exist_ok=True)\n",
        "\n",
        "      if len(os.listdir(sub_dir_path)) == 0:\n",
        "          continue\n",
        "      os.system(f\"ln -sf {sub_dir_path}/* {main_dir}/data/{modelver}\")\n",
        "\n",
        "import shutil\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def zip_outputs(outputs_path, zip_path, save_interval):\n",
        "  save_count = 0\n",
        "  last_backup_path = None\n",
        "\n",
        "  while True:\n",
        "    time.sleep(save_interval)\n",
        "\n",
        "    save_count += 1\n",
        "    backup_name = f\"{datetime.now().strftime('%m_%d')}_outputs_{datetime.now().strftime('%H:%M')}_{save_count}\"\n",
        "    backup_path = f\"{zip_path}/{backup_name}\"\n",
        "\n",
        "    if last_backup_path:\n",
        "      os.remove(last_backup_path)\n",
        "\n",
        "    try:\n",
        "      shutil.make_archive(backup_path, 'zip', root_dir=outputs_path)\n",
        "      print(f'ËæìÂá∫ÂõæÁâáÂ§á‰ªΩÊàêÂäü: {backup_path}.zip')\n",
        "      last_backup_path = f\"{backup_path}.zip\"\n",
        "    except Exception as e:\n",
        "      print(f\"ÂàõÂª∫Â§á‰ªΩÊó∂Âá∫Áé∞ÈîôËØØÔºö{e}\")\n",
        "\n",
        "import multiprocessing\n",
        "def start_background_task(target_func, *args):\n",
        "  p = multiprocessing.Process(target=target_func, args=args)\n",
        "  p.start()\n",
        "  return p\n",
        "\n",
        "def stop_background_task(process):\n",
        "  process.terminate()\n",
        "\n",
        "if use_drivemodels:\n",
        "  content_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ntpb1_Hbm65K"
      },
      "outputs": [],
      "source": [
        "# @title ÂêØÂä®\n",
        "import threading\n",
        "thread = threading.Thread(target=start_tunnle, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "if 'use_zipoutputs' in globals():\n",
        "    if use_zipoutputs:\n",
        "        outputs_path = f\"{main_dir}/data/outputs\"\n",
        "        back_zip = start_background_task(zip_outputs, outputs_path, zip_path, save_interval)\n",
        "else:\n",
        "    pass\n",
        "\n",
        "!python main.py 2>&1 | tee /content/output.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB8tkGv1i0Cn"
      },
      "source": [
        "### ÂÖ≥Èó≠ËøõÁ®ã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7MpeyTji3Db"
      },
      "outputs": [],
      "source": [
        "!ps -ef #ÊòæÁ§∫ËøõÁ®ã\n",
        "!pkill -f server.py\n",
        "!pkill -f pyngrok\n",
        "!pkill -f cloudflared\n",
        "#ÊùÄËøõÁ®ã"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xFS9SSqgTBgX",
        "tB8tkGv1i0Cn"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
